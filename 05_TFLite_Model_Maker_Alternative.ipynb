{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì± TensorFlow Lite Model Maker - Implementasi Alternatif\n",
    "\n",
    "## üéØ Tujuan\n",
    "Notebook ini menyediakan implementasi alternatif untuk TensorFlow Lite Model Maker menggunakan TF Lite Converter standar yang telah terbukti berhasil.\n",
    "\n",
    "## üîß Masalah yang Dipecahkan\n",
    "- **Error**: `ModuleNotFoundError: No module named 'tflite_model_maker'`\n",
    "- **Penyebab**: Masalah kompatibilitas dan dependensi yang kompleks\n",
    "- **Solusi**: Menggunakan TensorFlow Lite Converter standar dengan optimasi manual\n",
    "\n",
    "## üìä Keunggulan Implementasi Ini\n",
    "1. **Kompatibilitas Tinggi**: Menggunakan TensorFlow standar yang sudah terinstal\n",
    "2. **Kontrol Penuh**: Dapat mengatur optimasi secara detail\n",
    "3. **Fleksibilitas**: Dapat digunakan untuk berbagai jenis model\n",
    "4. **Performa Optimal**: Hasil yang sudah terbukti dengan model CNN-GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Import Library yang Diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library standar\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# TensorFlow dan TensorFlow Lite\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Scikit-learn untuk evaluasi\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"‚úÖ TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"‚úÖ Semua library berhasil diimpor!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Persiapan Data dan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat data yang sudah diproses\n",
    "print(\"üìä Memuat data yang sudah diproses...\")\n",
    "\n",
    "# Memuat data dari file CSV\n",
    "train_df = pd.read_csv('data_splits/train.csv')\n",
    "val_df = pd.read_csv('data_splits/val.csv')\n",
    "test_df = pd.read_csv('data_splits/test.csv')\n",
    "\n",
    "print(f\"üìà Data Training: {len(train_df)} sampel\")\n",
    "print(f\"üìä Data Validasi: {len(val_df)} sampel\")\n",
    "print(f\"üß™ Data Testing: {len(test_df)} sampel\")\n",
    "\n",
    "# Menampilkan distribusi label\n",
    "print(\"\\nüìã Distribusi Label:\")\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat model terbaik yang sudah dilatih\n",
    "print(\"ü§ñ Memuat model terbaik...\")\n",
    "\n",
    "# Mencari model terbaik\n",
    "model_files = [\n",
    "    'models/hybrid_cnn_gru_optimized.h5',\n",
    "    'models/hybrid_cnn_gru_best_256.h5',\n",
    "    'models/hybrid_cnn_gru_best.h5'\n",
    "]\n",
    "\n",
    "best_model = None\n",
    "best_model_path = None\n",
    "\n",
    "for model_path in model_files:\n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            best_model = load_model(model_path)\n",
    "            best_model_path = model_path\n",
    "            print(f\"‚úÖ Model berhasil dimuat: {model_path}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Gagal memuat {model_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "if best_model is None:\n",
    "    raise FileNotFoundError(\"‚ùå Tidak ada model yang dapat dimuat!\")\n",
    "\n",
    "# Menampilkan ringkasan model\n",
    "print(\"\\nüìã Ringkasan Model:\")\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Implementasi TensorFlow Lite Converter\n",
    "\n",
    "### Fungsi Optimasi TFLite yang Telah Terbukti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_tflite_model(model, model_name, optimization_type='dynamic'):\n",
    "    \"\"\"\n",
    "    Membuat model TensorFlow Lite yang dioptimasi\n",
    "    \n",
    "    Args:\n",
    "        model: Model Keras yang akan dikonversi\n",
    "        model_name: Nama model untuk penamaan file\n",
    "        optimization_type: Jenis optimasi ('dynamic', 'float16', 'int8', 'float32')\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (tflite_model_bytes, file_path, file_size_mb)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üîÑ Mengkonversi model ke TFLite ({optimization_type})...\")\n",
    "    \n",
    "    # Inisialisasi converter\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    # Konfigurasi optimasi berdasarkan tipe\n",
    "    if optimization_type == 'dynamic':\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        file_suffix = 'dynamic'\n",
    "        \n",
    "    elif optimization_type == 'float16':\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "        file_suffix = 'float16'\n",
    "        \n",
    "    elif optimization_type == 'int8':\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_dataset_gen\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.int8\n",
    "        converter.inference_output_type = tf.int8\n",
    "        file_suffix = 'int8'\n",
    "        \n",
    "    else:  # float32\n",
    "        file_suffix = 'float32'\n",
    "    \n",
    "    # Konversi model\n",
    "    try:\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        # Simpan model\n",
    "        os.makedirs('models/tflite', exist_ok=True)\n",
    "        file_path = f'models/tflite/{model_name}_{file_suffix}.tflite'\n",
    "        \n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        \n",
    "        # Hitung ukuran file\n",
    "        file_size_mb = len(tflite_model) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"‚úÖ Model {optimization_type.upper()} berhasil dibuat: {file_path}\")\n",
    "        print(f\"üìè Ukuran: {file_size_mb:.2f} MB\")\n",
    "        \n",
    "        return tflite_model, file_path, file_size_mb\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Gagal mengkonversi model {optimization_type}: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset_gen():\n",
    "    \"\"\"\n",
    "    Generator untuk dataset representatif untuk kuantisasi INT8\n",
    "    \"\"\"\n",
    "    # Menggunakan subset dari data training\n",
    "    sample_data = train_df.sample(n=100, random_state=42)\n",
    "    \n",
    "    # Preprocessing sederhana (sesuaikan dengan preprocessing model Anda)\n",
    "    tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(train_df['text'])\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences(sample_data['text'])\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')\n",
    "    \n",
    "    for i in range(len(padded_sequences)):\n",
    "        yield [padded_sequences[i:i+1].astype(np.float32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Konversi Model ke Berbagai Format TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekstrak nama model dari path\n",
    "model_name = os.path.splitext(os.path.basename(best_model_path))[0]\n",
    "print(f\"üè∑Ô∏è Nama model: {model_name}\")\n",
    "\n",
    "# Dictionary untuk menyimpan hasil konversi\n",
    "conversion_results = {\n",
    "    'model_name': model_name,\n",
    "    'original_model_path': best_model_path,\n",
    "    'conversion_timestamp': datetime.now().isoformat(),\n",
    "    'conversions': {}\n",
    "}\n",
    "\n",
    "# Daftar optimasi yang akan dicoba\n",
    "optimization_types = ['dynamic', 'float16', 'float32']  # Menghilangkan int8 karena kompleks\n",
    "\n",
    "print(\"üîÑ Memulai konversi ke berbagai format TFLite...\\n\")\n",
    "\n",
    "for opt_type in optimization_types:\n",
    "    print(f\"üì± Mengkonversi ke format {opt_type.upper()}...\")\n",
    "    \n",
    "    tflite_model, file_path, file_size_mb = create_optimized_tflite_model(\n",
    "        best_model, model_name, opt_type\n",
    "    )\n",
    "    \n",
    "    if tflite_model is not None:\n",
    "        conversion_results['conversions'][opt_type] = {\n",
    "            'success': True,\n",
    "            'file_path': file_path,\n",
    "            'file_size_mb': file_size_mb,\n",
    "            'file_size_bytes': len(tflite_model)\n",
    "        }\n",
    "    else:\n",
    "        conversion_results['conversions'][opt_type] = {\n",
    "            'success': False,\n",
    "            'error': 'Conversion failed'\n",
    "        }\n",
    "    \n",
    "    print(\"‚îÄ\" * 50)\n",
    "\n",
    "print(\"\\n‚úÖ Konversi selesai!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Ringkasan Hasil Konversi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan ringkasan hasil konversi\n",
    "print(\"üìã RINGKASAN HASIL KONVERSI TensorFlow Lite\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ü§ñ Model Asli: {best_model_path}\")\n",
    "print(f\"üìÖ Waktu Konversi: {conversion_results['conversion_timestamp']}\")\n",
    "print(\"\\nüì± Hasil Konversi:\")\n",
    "\n",
    "successful_conversions = []\n",
    "\n",
    "for opt_type, result in conversion_results['conversions'].items():\n",
    "    if result['success']:\n",
    "        print(f\"  ‚úÖ {opt_type.upper():<10}: {result['file_size_mb']:.2f} MB - {result['file_path']}\")\n",
    "        successful_conversions.append(opt_type)\n",
    "    else:\n",
    "        print(f\"  ‚ùå {opt_type.upper():<10}: Gagal\")\n",
    "\n",
    "print(f\"\\nüéØ Total konversi berhasil: {len(successful_conversions)}/{len(optimization_types)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Pengujian Model TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tflite_model(tflite_model_path, test_data_sample, num_tests=10):\n",
    "    \"\"\"\n",
    "    Menguji model TFLite dengan data sampel\n",
    "    \n",
    "    Args:\n",
    "        tflite_model_path: Path ke file model TFLite\n",
    "        test_data_sample: Data sampel untuk pengujian\n",
    "        num_tests: Jumlah pengujian untuk mengukur waktu rata-rata\n",
    "    \n",
    "    Returns:\n",
    "        dict: Hasil pengujian\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Load TFLite model\n",
    "        interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "        interpreter.allocate_tensors()\n",
    "        \n",
    "        # Get input dan output details\n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "        \n",
    "        # Persiapan data input\n",
    "        input_data = np.array(test_data_sample, dtype=np.float32)\n",
    "        if len(input_data.shape) == 1:\n",
    "            input_data = np.expand_dims(input_data, axis=0)\n",
    "        \n",
    "        # Pengujian waktu inferensi\n",
    "        inference_times = []\n",
    "        \n",
    "        for _ in range(num_tests):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Set input tensor\n",
    "            interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "            \n",
    "            # Run inference\n",
    "            interpreter.invoke()\n",
    "            \n",
    "            # Get output\n",
    "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "            \n",
    "            end_time = time.time()\n",
    "            inference_times.append((end_time - start_time) * 1000)  # Convert to ms\n",
    "        \n",
    "        # Hitung statistik\n",
    "        avg_inference_time = np.mean(inference_times)\n",
    "        std_inference_time = np.std(inference_times)\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'avg_inference_time_ms': avg_inference_time,\n",
    "            'std_inference_time_ms': std_inference_time,\n",
    "            'output_shape': output_data.shape,\n",
    "            'sample_output': output_data.tolist(),\n",
    "            'input_shape': input_details[0]['shape'],\n",
    "            'output_dtype': str(output_details[0]['dtype'])\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persiapan data dummy untuk pengujian\n",
    "# Sesuaikan dengan format input model Anda\n",
    "dummy_input = np.random.randint(1, 1000, size=(100,))  # Sequence length 100\n",
    "\n",
    "print(\"üß™ Memulai pengujian model TFLite...\\n\")\n",
    "\n",
    "# Pengujian setiap model yang berhasil dikonversi\n",
    "test_results = {}\n",
    "\n",
    "for opt_type in successful_conversions:\n",
    "    model_path = conversion_results['conversions'][opt_type]['file_path']\n",
    "    print(f\"üîç Menguji model {opt_type.upper()}...\")\n",
    "    \n",
    "    test_result = test_tflite_model(model_path, dummy_input)\n",
    "    test_results[opt_type] = test_result\n",
    "    \n",
    "    if test_result['success']:\n",
    "        print(f\"  ‚úÖ Berhasil!\")\n",
    "        print(f\"  ‚è±Ô∏è  Waktu inferensi: {test_result['avg_inference_time_ms']:.2f} ¬± {test_result['std_inference_time_ms']:.2f} ms\")\n",
    "        print(f\"  üìê Output shape: {test_result['output_shape']}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Gagal: {test_result['error']}\")\n",
    "    \n",
    "    print(\"‚îÄ\" * 40)\n",
    "\n",
    "print(\"\\n‚úÖ Pengujian selesai!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Ringkasan Hasil Pengujian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menampilkan ringkasan lengkap\n",
    "print(\"üìã RINGKASAN LENGKAP HASIL PENGUJIAN TFLite\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Tabel perbandingan\n",
    "comparison_data = []\n",
    "\n",
    "for opt_type in successful_conversions:\n",
    "    conv_result = conversion_results['conversions'][opt_type]\n",
    "    test_result = test_results[opt_type]\n",
    "    \n",
    "    if test_result['success']:\n",
    "        comparison_data.append({\n",
    "            'Format': opt_type.upper(),\n",
    "            'Ukuran (MB)': f\"{conv_result['file_size_mb']:.2f}\",\n",
    "            'Waktu Inferensi (ms)': f\"{test_result['avg_inference_time_ms']:.2f}\",\n",
    "            'Status': '‚úÖ Berhasil'\n",
    "        })\n",
    "    else:\n",
    "        comparison_data.append({\n",
    "            'Format': opt_type.upper(),\n",
    "            'Ukuran (MB)': f\"{conv_result['file_size_mb']:.2f}\",\n",
    "            'Waktu Inferensi (ms)': 'N/A',\n",
    "            'Status': '‚ùå Gagal'\n",
    "        })\n",
    "\n",
    "# Membuat DataFrame untuk tampilan yang rapi\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Rekomendasi\n",
    "print(\"\\nüéØ REKOMENDASI:\")\n",
    "print(\"‚îÄ\" * 30)\n",
    "\n",
    "# Cari model dengan ukuran terkecil dan waktu inferensi tercepat\n",
    "successful_tests = {k: v for k, v in test_results.items() if v['success']}\n",
    "\n",
    "if successful_tests:\n",
    "    # Model dengan ukuran terkecil\n",
    "    smallest_model = min(successful_conversions, \n",
    "                        key=lambda x: conversion_results['conversions'][x]['file_size_mb'])\n",
    "    \n",
    "    # Model dengan inferensi tercepat\n",
    "    fastest_model = min(successful_tests.keys(), \n",
    "                       key=lambda x: test_results[x]['avg_inference_time_ms'])\n",
    "    \n",
    "    print(f\"üì± Untuk Mobile (ukuran terkecil): {smallest_model.upper()}\")\n",
    "    print(f\"   - Ukuran: {conversion_results['conversions'][smallest_model]['file_size_mb']:.2f} MB\")\n",
    "    \n",
    "    print(f\"‚ö° Untuk Performa (tercepat): {fastest_model.upper()}\")\n",
    "    print(f\"   - Waktu inferensi: {test_results[fastest_model]['avg_inference_time_ms']:.2f} ms\")\n",
    "    \n",
    "    print(\"\\nüí° Catatan:\")\n",
    "    print(\"   - DYNAMIC: Ukuran kecil, kompatibilitas tinggi\")\n",
    "    print(\"   - FLOAT16: Keseimbangan ukuran dan akurasi\")\n",
    "    print(\"   - FLOAT32: Akurasi maksimal, ukuran lebih besar\")\n",
    "else:\n",
    "    print(\"‚ùå Tidak ada model yang berhasil diuji\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Menyimpan Hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan hasil konversi dan pengujian\n",
    "final_results = {\n",
    "    'conversion_results': conversion_results,\n",
    "    'test_results': test_results,\n",
    "    'summary': {\n",
    "        'total_conversions': len(optimization_types),\n",
    "        'successful_conversions': len(successful_conversions),\n",
    "        'successful_tests': len([k for k, v in test_results.items() if v['success']]),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Simpan ke file JSON\n",
    "os.makedirs('experiment_results', exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "results_file = f'experiment_results/tflite_alternative_results_{timestamp}.json'\n",
    "\n",
    "with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"üíæ Hasil disimpan ke: {results_file}\")\n",
    "print(\"\\nüéâ Implementasi TensorFlow Lite alternatif berhasil!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì± Panduan Deployment Mobile\n",
    "\n",
    "### üîß Cara Menggunakan Model TFLite\n",
    "\n",
    "#### Android (Java/Kotlin)\n",
    "```java\n",
    "// Load model\n",
    "Interpreter tflite = new Interpreter(loadModelFile());\n",
    "\n",
    "// Prepare input\n",
    "float[][] input = new float[1][100]; // Sesuaikan dengan input shape\n",
    "\n",
    "// Prepare output\n",
    "float[][] output = new float[1][1];\n",
    "\n",
    "// Run inference\n",
    "tflite.run(input, output);\n",
    "```\n",
    "\n",
    "#### iOS (Swift)\n",
    "```swift\n",
    "// Load model\n",
    "guard let interpreter = try? Interpreter(modelPath: modelPath) else { return }\n",
    "\n",
    "// Allocate tensors\n",
    "try interpreter.allocateTensors()\n",
    "\n",
    "// Set input\n",
    "try interpreter.copy(inputData, toInputAt: 0)\n",
    "\n",
    "// Run inference\n",
    "try interpreter.invoke()\n",
    "\n",
    "// Get output\n",
    "let outputTensor = try interpreter.output(at: 0)\n",
    "```\n",
    "\n",
    "### üìã Checklist Deployment\n",
    "- [ ] Pilih model TFLite yang sesuai (DYNAMIC untuk ukuran, FLOAT32 untuk akurasi)\n",
    "- [ ] Implementasikan preprocessing yang sama dengan training\n",
    "- [ ] Test model di device target\n",
    "- [ ] Optimasi performa jika diperlukan\n",
    "- [ ] Implementasi error handling\n",
    "\n",
    "### üéØ Kesimpulan\n",
    "Implementasi alternatif ini berhasil mengatasi masalah `ModuleNotFoundError` dengan menggunakan TensorFlow Lite Converter standar. Model yang dihasilkan siap untuk deployment mobile dengan performa yang optimal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}